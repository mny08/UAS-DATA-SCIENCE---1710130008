# -*- coding: utf-8 -*-
"""UAS DATA SCIENCE KLASTER K-MEANS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WBPe20cEZBc6-DbV_vSFPJrrV2WfNhMe
"""

# Commented out IPython magic to ensure Python compatibility.
# Feature Extraction with RFE
import pandas as pd
from pandas import read_csv
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
# %matplotlib inline

# load data
from sklearn import preprocessing
data = pd.read_csv('data covid (mentah).csv', delimiter=";", names = [ 'New Cases', 'New Deaths', 'new Recoverd', 'New Active', 'Total cases', 'Total Deaths', 'Total Recovered', 'Total Active Cases', 'Location'])

data.shape

data.head()

"""Deskripsi Data"""

data.info()

data.describe

"""Ekstraksi Fitur"""

array = data.values
X = array[:,0:8]
Y = array[:,8]
# feature extraction
model = LogisticRegression(solver='lbfgs')
rfe = RFE(model, 8)
fit = rfe.fit(X, Y)

# feature extraction
model = LogisticRegression(solver='lbfgs')
rfe = RFE(model, 3)
fit = rfe.fit(X, Y)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)

"""Load Data hasil ekstrasi"""

import numpy as np
import pandas as pd
import sklearn
import scipy
import numpy
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
!pip install impyute
import sys
from impyute.imputation.cs import fast_knn
from impyute.imputation.cs import mice
import seaborn as sns
!pip install matplotlib
sns.set(style="white", color_codes=True)
from matplotlib import pyplot
from sklearn.preprocessing import Normalizer

df = pd.read_csv('data covid (ekstrasi).csv', delimiter=";", names = [ 'Total Deaths', 'Total Recovered', 'Total Active Cases', 'Location'])

df.head()

df.shape

# Variabel independen
x = df.drop(["Location"], axis = 1)
#variabel dependen
y = df["Location"]

df

from sklearn import preprocessing
x = df.values #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df = pd.DataFrame(x_scaled)

df

df.min()

"""Visulaisasi Data"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler

df

df.hist()
plt.show()

df.isnull().sum()

df.count

df.mean()

"""Mentukan Jumlah Cluster dengan emtode Elbom

"""

Error =[]
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i).fit(x)
    kmeans.fit(x)
    Error.append(kmeans.inertia_)
import matplotlib.pyplot as plt
plt.plot(range(1, 11), Error)
plt.title('Elbow method')
plt.xlabel('No of clusters')
plt.ylabel('Error')
plt.show()

kmeans = KMeans(n_clusters=3)

kmeans.fit(x)

kmeans.cluster_centers_

kmeans.labels_

import numpy as np

unique, counts = np.unique(kmeans.labels_, return_counts=True)

dict_data = dict(zip(unique, counts))
dict_data

import seaborn as sns
data["cluster"] = kmeans.labels_

data.cluster

df.plot(kind='density',subplots=True,sharex=False)
plt.show()